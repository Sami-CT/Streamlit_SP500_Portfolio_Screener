{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "891c60f4-53ff-4d75-9a49-5ec3f2225c45",
   "metadata": {},
   "source": [
    "# Projet Data viz\n",
    "\n",
    "Dans le cadre de ce projet, nous avons notre propre base de données en nous appuyant sur l'API de Yahoo Finance grâce au package Python `yfinance`. L'objectif principal était de collecter des données financières détaillées sur les entreprises qui composent l'indice S&P 500, ainsi que des informations historiques sur l'indice lui-même.\n",
    "\n",
    "## Collecte des Tickers et Construction de la Base\n",
    "\n",
    "Pour identifier les entreprises du S&P 500, j'ai avons utilisé une base de données en accès libre disponible sur le site DataHub.io. Cette ressource fournit une liste complète des tickers des entreprises cotées au sein de cet indice, accompagnée de leurs secteurs et sous-secteurs d'activité (GICS). Ces tickers sont essentiels pour accéder aux données financières via l'API.\n",
    "\n",
    "Lien vers la base de données utilisée :\n",
    "https://datahub.io/core/s-and-p-500-companies/\n",
    "\n",
    "Le fichier source contient les informations suivantes (entre-autres) :\n",
    "\n",
    "- **Symbol :** Le ticker boursier (ou symbole) unique de chaque entreprise.\n",
    "- **Security :** Le nom complet de l'entreprise.\n",
    "- **GICS Sector :** Le secteur d'activité auquel l'entreprise appartient.\n",
    "- **GICS Sub-Industry :** Le sous-secteur d'activité plus spécifique.\n",
    "\n",
    "Avant d'utiliser ces tickers dans le code, j'ai remplacé les points (.) présents dans certains tickers par des tirets (-) afin de respecter le format attendu par Yahoo Finance.\n",
    "\n",
    "## Implémentation en Python pour Importer les Données\n",
    "\n",
    "### Description du Code : Téléchargement et Préparation des Données du S&P 500\n",
    "\n",
    "Ce script a pour objectif de télécharger les données historiques des entreprises composant l'indice S&P 500, de les enrichir avec des métadonnées, puis de fusionner ces données avec l'historique de l'indice S&P 500. Enfin, les données consolidées sont exportées dans un fichier CSV.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Importation des Librairies et des Données Initiales\n",
    "\n",
    "- **`pandas`** : Utilisé pour manipuler les données tabulaires et effectuer des opérations comme la lecture et l’écriture de fichiers CSV.\n",
    "- **`yfinance`** : Utilisé pour interagir avec l’API de Yahoo Finance et récupérer des données financières historiques.\n",
    "\n",
    "Le fichier CSV contenant les informations des entreprises du S&P 500 est téléchargé depuis [DataHub.io](https://datahub.io/core/s-and-p-500-companies/). Ce fichier contient :\n",
    "- **Symbol** : Ticker boursier unique de chaque entreprise.\n",
    "- **Security** : Nom de l'entreprise.\n",
    "- **GICS Sector** : Secteur d'activité.\n",
    "- **GICS Sub-Industry** : Sous-secteur d'activité.\n",
    "\n",
    "Une étape de prétraitement ajuste les tickers pour remplacer les points (`.`) par des tirets (`-`), ce qui correspond au format attendu par Yahoo Finance.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Fonction pour Interroger l'API de Yahoo Finance\n",
    "\n",
    "Une fonction **`api_request(a, b, c, d)`** est définie pour :\n",
    "- **`a`** : Ticker de l'action ou de l'indice.\n",
    "- **`b`**, **`c`** : Dates de début et de fin pour la récupération des données.\n",
    "- **`d`** : Fréquence des données (ex. : journalière, horaire, etc.).\n",
    "\n",
    "Elle retourne un tableau contenant les données de prix historiques pour le ticker spécifié.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Téléchargement des Données Historiques de l'Indice S&P 500\n",
    "\n",
    "Les données de l’indice S&P 500, identifiées par le ticker `^GSPC`, sont téléchargées pour la période allant du 1er novembre 2019 au 1er novembre 2024 avec une fréquence quotidienne. Une fois récupérées, elles sont transformées pour ne conserver que deux colonnes :\n",
    "- **Date** : Date des données.\n",
    "- **SP500 Close** : Prix de clôture de l’indice.\n",
    "\n",
    "Ces données serviront de référence (benchmark) pour les entreprises du S&P 500.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Téléchargement des Données des Entreprises du S&P 500\n",
    "\n",
    "Une boucle parcourt chaque ligne du fichier des constituants du S&P 500 :\n",
    "1. **Extraction des informations par entreprise** : \n",
    "   - **`Symbol`** : Ticker de l'entreprise.\n",
    "   - **`Security`** : Nom de l'entreprise.\n",
    "   - **`GICS Sector`** et **`GICS Sub-Industry`** : Métadonnées sur le secteur et sous-secteur d'activité.\n",
    "   \n",
    "2. **Récupération des données historiques via l’API** :  \n",
    "   Les données historiques de l’action sont récupérées sur la même période que pour l’indice S&P 500 (1er novembre 2019 au 1er novembre 2024).\n",
    "\n",
    "3. **Ajout des métadonnées** :  \n",
    "   Les colonnes suivantes sont ajoutées aux données de l’action pour enrichir les informations :\n",
    "   - **Security** : Nom complet de l'entreprise.\n",
    "   - **GICS Sector** : Secteur d’activité.\n",
    "   - **GICS Sub-Industry** : Sous-secteur d’activité.\n",
    "   - **Symbol** : Ticker de l’entreprise.\n",
    "\n",
    "4. **Fusion des données** :  \n",
    "   Les données de chaque entreprise sont ajoutées au DataFrame principal **`data`** à l’aide de la fonction **`pd.concat`**.\n",
    "\n",
    "Un compteur affiche l’état d’avancement de la boucle pour suivre la progression.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. Fusion avec les Données de l'Indice S&P 500\n",
    "\n",
    "Une fusion est effectuée entre les données des entreprises du S&P 500 et celles de l'indice S&P 500, en utilisant la colonne **Date** comme clé commune. Cette étape permet d’ajouter la valeur de clôture de l’indice à chaque ligne correspondant à une entreprise.\n",
    "\n",
    "---\n",
    "\n",
    "#### 6. Exportation des Données Consolidées\n",
    "\n",
    "- Les données fusionnées et enrichies sont exportées dans un fichier CSV nommé **`imported_data.csv`**.\n",
    "- Le fichier est structuré avec des colonnes contenant les données historiques des prix, les métadonnées des entreprises, et la valeur de clôture de l’indice S&P 500.\n",
    "\n",
    "---\n",
    "\n",
    "### Résumé des Étapes\n",
    "1. Téléchargement des informations des entreprises du S&P 500 depuis une base de données en ligne.\n",
    "2. Récupération des données historiques des entreprises et de l'indice S&P 500 via l'API Yahoo Finance.\n",
    "3. Ajout de métadonnées (secteur, sous-secteur, etc.) pour chaque entreprise.\n",
    "4. Fusion des données avec l'indice S&P 500 pour inclure un benchmark.\n",
    "5. Exportation des données consolidées dans un fichier CSV.\n",
    "\n",
    "Ce script génère une base de données prête pour une analyse approfondie des performances des actions du S&P 500 sur une période donnée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7c0a46-c5db-4559-bf26-766401c7722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "constituents = pd.read_csv(\"https://datahub.io/core/s-and-p-500-companies/_r/-/data/constituents.csv\")\n",
    "constituents[\"Symbol\"] = constituents[\"Symbol\"].str.replace(r\"\\.\", \"-\", regex=True)\n",
    "cn = len(constituents)\n",
    "\n",
    "def api_request(a, b, c, d):\n",
    "    x = yf.Ticker(a)\n",
    "    y = x.history(start=b, end=c, interval=d)\n",
    "    return y\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "print(\"Téléchargement des données du S&P 500...\")\n",
    "sp500 = api_request(\"^GSPC\", \"2019-11-01\", \"2024-11-01\", \"1d\")\n",
    "sp500 = sp500.reset_index()\n",
    "sp500 = sp500[[\"Date\", \"Close\"]].rename(columns={\"Close\": \"SP500 Close\"})\n",
    "\n",
    "for i, row in constituents.iterrows():\n",
    "    symbol = row[\"Symbol\"]\n",
    "    security = row[\"Security\"]\n",
    "    sector = row[\"GICS Sector\"]\n",
    "    industry = row[\"GICS Sub-Industry\"]\n",
    "\n",
    "    print(f\"[{i + 1}/{cn}] {symbol}...\", end=\"\")\n",
    "    history = api_request(symbol, \"2019-11-01\", \"2024-11-01\", \"1d\")\n",
    "    print(\" X\")\n",
    "    history = history.reset_index()\n",
    "\n",
    "    history.insert(0, \"Security\", security)\n",
    "    history[\"GICS Sector\"] = sector\n",
    "    history[\"GICS Sub-Industry\"] = industry\n",
    "    history[\"Symbol\"] = symbol\n",
    "\n",
    "    data = pd.concat([data, history])\n",
    "\n",
    "\n",
    "print(\"Fusion des données avec le S&P 500...\")\n",
    "data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "sp500[\"Date\"] = pd.to_datetime(sp500[\"Date\"])\n",
    "data = pd.merge(data, sp500, on=\"Date\", how=\"left\")\n",
    "\n",
    "print()\n",
    "print(50 * \"*\")\n",
    "print(\"Données en cours d'exportation...\")\n",
    "data.to_csv(\"imported_data.csv\", sep=\";\", index=False)\n",
    "print(\"Données exportées avec succès !\")\n",
    "print(50 * \"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301a654b-7512-4a28-9bae-650a67391afb",
   "metadata": {},
   "source": [
    "### Nettoyage et Enrichissement des Données : Explication du Code\n",
    "\n",
    "Le code présenté effectue un nettoyage approfondi des données et les enrichit avec une variété d'indicateurs financiers avancés pour évaluer les performances et la volatilité des actions. Voici une explication détaillée des différentes étapes et calculs réalisés :\n",
    "\n",
    "---\n",
    "\n",
    "#### Importation des Données\n",
    "- Les données sont importées à partir du fichier CSV **`imported_data.csv`**, contenant les informations sur les actions et l'indice S&P 500.\n",
    "\n",
    "---\n",
    "\n",
    "#### Calcul des Indicateurs de Base\n",
    "\n",
    "1. **Performance Intraday (%)** :  \n",
    "   $$\n",
    "   \\text{Performance Intraday (\\%)} = \\frac{\\text{Close} - \\text{Open}}{\\text{Open}} \\times 100\n",
    "   $$\n",
    "\n",
    "2. **Moyenne Mobile sur 30 Jours (USD)** :  \n",
    "   $$\n",
    "   \\text{30-Day Moving Average (USD)} = \\text{Rolling Mean (Close, 30 jours)}\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "#### Calcul des Rendements et des Rendements Excédentaires\n",
    "\n",
    "1. **Rendement de l'Actif** :  \n",
    "   $$\n",
    "   \\text{Asset Return} = \\text{pct\\_change}(\\text{Close})\n",
    "   $$\n",
    "\n",
    "2. **Rendement de l'Indice S&P 500** :  \n",
    "   $$\n",
    "   \\text{Benchmark Return} = \\text{pct\\_change}(\\text{SP500 Close})\n",
    "   $$\n",
    "\n",
    "3. **Rendement Excédentaire** :  \n",
    "   $$\n",
    "   \\text{Excess Return} = \\text{Asset Return} - \\text{Benchmark Return}\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "#### Calcul du Ratio d'Information\n",
    "\n",
    "Le **Ratio d'Information** est calculé comme suit pour chaque groupe d'actions :\n",
    "$$\n",
    "\\text{Information Ratio} = \\frac{\\text{Moyenne des Rendements Excédentaires}}{\\text{Écart-Type des Rendements Excédentaires}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Conversion des Rendements en Pourcentages\n",
    "\n",
    "- Les colonnes des rendements ($\\text{Asset Return}$, $\\text{Benchmark Return}$, $\\text{Excess Return}$) sont multipliées par 100 pour obtenir des pourcentages.\n",
    "\n",
    "---\n",
    "\n",
    "#### Calcul du Beta Glissant (30 Jours)\n",
    "\n",
    "Le **Rolling Beta** (Beta sur une période glissante de 30 jours) est calculé pour chaque groupe d'actions comme suit :\n",
    "$$\n",
    "\\text{Rolling Beta (30 days)} = \\frac{\\text{Rolling Cov}(\\text{Asset Return}, \\text{Benchmark Return})}{\\text{Rolling Var}(\\text{Benchmark Return})}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Ajout de Mesures de Risque\n",
    "\n",
    "1. **Max Drawdown sur 30 Jours** :  \n",
    "   Le **Drawdown** mesure la perte maximale par rapport au point le plus haut atteint dans une fenêtre glissante de 30 jours :\n",
    "   $$\n",
    "   \\text{Max Drawdown} = \\min\\left(\\frac{\\text{Valeurs Cumulées}}{\\max(\\text{Valeurs Cumulées})} - 1\\right)\n",
    "   $$\n",
    "\n",
    "2. **VaR (5%) sur 30 Jours** :  \n",
    "   La **Value at Risk (VaR)** correspond au rendement minimum à un niveau de confiance de 5% dans une fenêtre de 30 jours :\n",
    "   $$\n",
    "   \\text{VaR (5\\%)} = \\text{Percentile à 5\\% des Rendements dans la Fenêtre}\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "#### Calcul des Performances Cumulées YTD (Year-To-Date)\n",
    "\n",
    "Pour chaque action, la performance cumulée depuis le début de l'année en cours est calculée :\n",
    "$$\n",
    "\\text{YTD Performance (\\%)} = \\frac{\\text{Close} - \\text{First Close of the Year}}{\\text{First Close of the Year}} \\times 100\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Renommage et Nettoyage des Données\n",
    "\n",
    "Les colonnes sont renommées pour une meilleure lisibilité, et certaines colonnes inutiles sont supprimées. Par exemple :  \n",
    "- Renommage des colonnes liées aux prix :  \n",
    "  - `Open` → **`Price Open (USD)`**\n",
    "  - `Close` → **`Price Close (USD)`**\n",
    "  - `SP500 Close` → **`S&P500 Close (USD)`**\n",
    "\n",
    "---\n",
    "\n",
    "#### Calcul d'Indicateurs Complémentaires\n",
    "\n",
    "1. **Amplitude des Prix (USD)** :  \n",
    "   $$\n",
    "   \\text{Price Range (USD)} = \\text{Price High (USD)} - \\text{Price Low (USD)}\n",
    "   $$\n",
    "\n",
    "2. **Variation des Prix (USD et %)** :  \n",
    "   - En valeur absolue :  \n",
    "     $$\n",
    "     \\text{Price Change (USD)} = \\text{Price Close (USD)} - \\text{Price Open (USD)}\n",
    "     $$\n",
    "   - En pourcentage :  \n",
    "     $$\n",
    "     \\text{Price Change (\\%)} = \\frac{\\text{Price Change (USD)}}{\\text{Price Open (USD)}} \\times 100\n",
    "     $$\n",
    "\n",
    "3. **Volatilité (%)** :  \n",
    "   $$\n",
    "   \\text{Volatility (\\%)} = \\frac{\\text{Price High (USD)} - \\text{Price Low (USD)}}{\\text{Price Low (USD)}} \\times 100\n",
    "   $$\n",
    "\n",
    "4. **Rendement du Dividende (%)** :  \n",
    "   $$\n",
    "   \\text{Dividend Yield (\\%)} = \\frac{\\text{Dividends}}{\\text{Price Close (USD)}} \\times 100\n",
    "   $$\n",
    "\n",
    "5. **Prix Moyen (USD)** :  \n",
    "   $$\n",
    "   \\text{Average Price (USD)} = \\frac{\\text{Price Open (USD)} + \\text{Price Close (USD)}}{2}\n",
    "   $$\n",
    "\n",
    "6. **Ratio Volume/Prix** :  \n",
    "   $$\n",
    "   \\text{Volume to Price Ratio} = \\frac{\\text{Volume}}{\\text{Price Close (USD)}}\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "#### Exportation des Données\n",
    "\n",
    "Les données nettoyées et enrichies sont exportées dans un fichier CSV nommé **`data.csv`**, indexé par le ticker et la date, pour faciliter les analyses futures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfbd2e7-305b-4228-ad2c-f74569fb26bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"imported_data.csv\", sep=\";\")\n",
    "\n",
    "data[\"Performance Intraday (%)\"] = ((data[\"Close\"] - data[\"Open\"]) / data[\"Open\"]) * 100\n",
    "data[\"30-Day Moving Average (USD)\"] = data[\"Close\"].rolling(window=30).mean()\n",
    "\n",
    "\n",
    "data[\"Asset Return\"] = data.groupby(\"Symbol\")[\"Close\"].pct_change()  # Rendements de l'actif\n",
    "data[\"Benchmark Return\"] = data[\"SP500 Close\"].pct_change()         # Rendements du S&P 500\n",
    "\n",
    "\n",
    "data[\"Excess Return\"] = data[\"Asset Return\"] - data[\"Benchmark Return\"]\n",
    "\n",
    "\n",
    "def calculate_information_ratio(group):\n",
    "    mean_excess_return = group[\"Excess Return\"].mean()  # Moyenne des rendements excédentaires\n",
    "    tracking_error = group[\"Excess Return\"].std()       # Écart-type des rendements excédentaires\n",
    "    if tracking_error == 0:\n",
    "        return np.nan  # Éviter la division par zéro\n",
    "    return mean_excess_return / tracking_error\n",
    "\n",
    "\n",
    "information_ratios = data.groupby(\"Symbol\").apply(calculate_information_ratio)\n",
    "information_ratios.name = \"Information Ratio\"\n",
    "\n",
    "\n",
    "data = data.merge(information_ratios, on=\"Symbol\", how=\"left\")\n",
    "\n",
    "data[\"Asset Return (%)\"] = data[\"Asset Return\"] * 100\n",
    "data[\"Benchmark Return (%)\"] = data[\"Benchmark Return\"] * 100\n",
    "data[\"Excess Return (%)\"] = data[\"Excess Return\"] * 100\n",
    "columns_to_drop = [\"Asset Return\", \"Benchmark Return\", \"Excess Return\", \"Information Ratio_x\", \"Information Ratio_y\"]\n",
    "data = data.drop(columns=columns_to_drop, errors=\"ignore\")\n",
    "\n",
    "data[\"Asset Return\"] = data[\"Asset Return (%)\"] / 100  # Convert to fraction\n",
    "data[\"Benchmark Return\"] = data[\"Benchmark Return (%)\"] / 100  # Convert to fraction\n",
    "\n",
    "def calculate_rolling_beta(group):\n",
    "    rolling_cov = group[\"Asset Return\"].rolling(window=30).cov(group[\"Benchmark Return\"])\n",
    "    rolling_var = group[\"Benchmark Return\"].rolling(window=30).var()\n",
    "    return rolling_cov / rolling_var\n",
    "\n",
    "data[\"Rolling Beta (30 days)\"] = (\n",
    "    data.groupby(\"Symbol\", group_keys=False)\n",
    "    .apply(calculate_rolling_beta)\n",
    ")\n",
    "\n",
    "\n",
    "def add_max_drawdown_30_days(data):\n",
    "\n",
    "    column_returns = \"Asset Return (%)\"\n",
    "    max_drawdown_column_name = \"Max Drawdown (30 days)\"\n",
    "    window_size = 30\n",
    "\n",
    "    if column_returns not in data.columns:\n",
    "        raise ValueError(f\"La colonne '{column_returns}' n'existe pas dans le DataFrame.\")\n",
    "\n",
    "\n",
    "    def calculate_max_drawdown_window(returns):\n",
    "        if len(returns) < window_size: \n",
    "            return np.nan\n",
    "        \n",
    "        cumulative_returns = np.cumprod(1 + returns / 100) \n",
    "        \n",
    "        drawdown = (cumulative_returns / np.maximum.accumulate(cumulative_returns)) - 1\n",
    "        return drawdown.min()  # Drawdown le plus sévère\n",
    "\n",
    "\n",
    "    try:\n",
    "        data[max_drawdown_column_name] = (\n",
    "            data.groupby(\"Symbol\")[column_returns]\n",
    "            .rolling(window=window_size)\n",
    "            .apply(calculate_max_drawdown_window, raw=True)\n",
    "            .reset_index(level=0, drop=True)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du calcul du Max Drawdown : {e}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def add_var_30_days(data):\n",
    "\n",
    "    column_returns = \"Asset Return (%)\"\n",
    "    var_column_name = \"VaR (5%) (30 days)\"\n",
    "    window_size = 30\n",
    "    confidence_level = 5\n",
    "\n",
    "    if column_returns not in data.columns:\n",
    "        raise ValueError(f\"La colonne '{column_returns}' n'existe pas dans le DataFrame.\")\n",
    "\n",
    "\n",
    "    def calculate_var_window(returns):\n",
    "        if len(returns) < window_size:\n",
    "            return np.nan\n",
    "        return np.percentile(returns, confidence_level)\n",
    "\n",
    "\n",
    "    data[var_column_name] = (\n",
    "        data.groupby(\"Symbol\")[column_returns]\n",
    "        .rolling(window=window_size)\n",
    "        .apply(calculate_var_window, raw=True)\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "data = add_max_drawdown_30_days(data)\n",
    "data = add_var_30_days(data)\n",
    "\n",
    "def add_daily_ytd(data):\n",
    "\n",
    "    data[\"Date\"] = pd.to_datetime(data[\"Date\"], utc=True)\n",
    "    \n",
    "    data = data.sort_values([\"Symbol\", \"Date\"])\n",
    "    \n",
    "    def calculate_daily_ytd(group):\n",
    "\n",
    "        group[\"Year\"] = group[\"Date\"].dt.year\n",
    "        first_close_per_year = group.groupby(\"Year\")[\"Close\"].transform(\"first\")\n",
    "        \n",
    "        group[\"YTD Performance (%)\"] = ((group[\"Close\"] - first_close_per_year) / first_close_per_year) * 100\n",
    "        \n",
    "        if group[\"Year\"].min() == data[\"Date\"].dt.year.min():\n",
    "            group.loc[group[\"Year\"] == data[\"Date\"].dt.year.min(), \"YTD Performance (%)\"] = np.nan\n",
    "        \n",
    "        return group\n",
    "\n",
    "    data = data.groupby(\"Symbol\", group_keys=False).apply(calculate_daily_ytd)\n",
    "    data = data.drop(columns=[\"Year\"])  # Clean up temporary column\n",
    "\n",
    "    return data\n",
    "\n",
    "    \n",
    "data = add_daily_ytd(data)\n",
    "\n",
    "def get_data():\n",
    "    return data\n",
    "\n",
    "data = data.rename(columns={\n",
    "    \"Symbol\": \"Ticker\",\n",
    "    \"Open\": \"Price Open (USD)\",\n",
    "    \"High\": \"Price High (USD)\",\n",
    "    \"Low\": \"Price Low (USD)\",\n",
    "    \"Close\": \"Price Close (USD)\",\n",
    "    \"SP500 Close\": \"S&P500 Close (USD)\"\n",
    "    })\n",
    "\n",
    "data = data.drop(columns=[\"Stock Splits\"])\n",
    "data = data.drop(columns=[\"Asset Return\"])\n",
    "data = data.drop(columns=[\"Benchmark Return\"])\n",
    "\n",
    "data[\"Price Range (USD)\"] = data[\"Price High (USD)\"] - data[\"Price Low (USD)\"]\n",
    "data[\"Price Change (USD)\"] = data[\"Price Close (USD)\"] - data[\"Price Open (USD)\"]\n",
    "data[\"Price Change (%)\"] = (data[\"Price Close (USD)\"] - data[\"Price Open (USD)\"]) / data[\"Price Open (USD)\"] * 100\n",
    "data[\"Volatility (%)\"] = (data[\"Price High (USD)\"] - data[\"Price Low (USD)\"]) / data[\"Price Low (USD)\"] * 100\n",
    "data[\"Dividend Yield (%)\"] = data[\"Dividends\"] / data[\"Price Close (USD)\"] * 100\n",
    "data[\"Average Price (USD)\"] = (data[\"Price Open (USD)\"] + data[\"Price Close (USD)\"]) / 2\n",
    "data[\"Volume to Price Ratio\"] = data[\"Volume\"] / data[\"Price Close (USD)\"]\n",
    "\n",
    "data[\"Date\"] = pd.to_datetime(data[\"Date\"], utc=True)\n",
    "data[\"Date\"] = data[\"Date\"].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "data = data.sort_values(by=[\"Ticker\", \"Date\"])\n",
    "data = data.set_index([\"Ticker\", \"Date\"])\n",
    "\n",
    "print()\n",
    "print(50 * \"*\")\n",
    "print(\"Données en cours d'exportation...\")\n",
    "data.to_csv(\"data.csv\", sep=\";\", index=True)\n",
    "print(\"Données exportées avec succès !\")\n",
    "print(50 * \"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1ba2be-d597-4ced-ad9c-342157e0f0ec",
   "metadata": {},
   "source": [
    "Au total, nous avons 624 247 uniques observations pour 503 entreprises côtées en bourse."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
